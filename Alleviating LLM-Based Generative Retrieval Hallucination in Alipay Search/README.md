## ALLEVIATING LLM-BASED GENERATIVE RETRIEVAL HALLUCINATION IN ALIPAY SEARCH
https://dl.acm.org/doi/10.1145/3726302.3731951

### 1. The Problem: Generative Retrieval and Hallucination

In search systems, especially in scenarios like Alipay's Fund and Insurance Search, users input all kinds of queries, often with complex intentions. Generative retrieval (GR) powered by Large Language Models (LLMs)—such as GPT, Llama, or Qwen—has shown strong capability to interpret these complex queries and suggest relevant documents or products.

**However, there's a problem:** LLMs are prone to "hallucination." That means, even if they perform well, sometimes they generate irrelevant or incorrect results, potentially suggesting documents that don't actually match the user's needs. This hurts the user experience and business objectives.

### 2. Our Solution: An Optimized GR Framework

We propose a new framework to directly address the hallucination in LLM-based retrieval models. It includes two main modules:

- **Knowledge Distillation Reasoning**
- **Decision Agent**

#### Knowledge Distillation Reasoning

Let's say you have a small student model that isn't very smart, and a much larger, knowledgeable teacher. If you want the student to become smarter, you can have the teacher "explain" not just the answer, but also the reasoning behind it.

Here's what we do in practice:

- **Data Construction:** We build a training dataset from pairs of queries and documents, labeled as relevant or irrelevant. The relevant pairs come from existing data; for irrelevant pairs, we sample potential candidates using a preliminary retrieval model and double-check them with several LLMs in an ensemble to filter out anything possibly relevant.
- **Reasoning Generation:** For each query-document pair (both relevant and irrelevant), a _powerful_ LLM generates a reason—an explicit explanation of why a document is (or isn't) relevant to the query.
- **Knowledge Distillation:** We then fine-tune our smaller GR model using this enriched data, which contains not only the relevance labels but also the explanations generated by the larger model. This trains the smaller model not just to memorize answers but to actually _think_ about relevance the way the teacher does.

This process is much like a student learning better by understanding the logic of the teacher's answers, not just the answers themselves.

#### Decision Agent

Even after smarter training, hallucination can still persist—a single process isn't always perfect. So, after the initial retrieval, we add another layer of checking:

- We use traditional retrieval models (like classic sparse or dense retrievers) to gather more documents related to the GR output.
- For each candidate, we ask a strong LLM to assess the relevance again, but this time from multiple perspectives (e.g., checking product company, type, duration, etc.).
- Only documents that pass this multi-perspective test are kept as final results.

Think of it as a double-checked fallback: before showing results to users, we pass them through an additional expert filter to catch and remove mistakes the first round didn't notice.

### 3. Why This Works (Results)

Through a series of experiments and A/B tests in Alipay's live search system, we found:

- Removing the _reasoning_ module led to a ~2% drop in accuracy,
- Removing the _decision agent_ led to further drops,
- Our framework, when fully applied, significantly improved both offline accuracy and live user engagement and business metrics (such as Clicks and Trades) 3726302.3731951.pdf.

### 4. Advantages of Our Approach

- **No need for extra manual annotation:** The process is automated using LLMs.
- **Easily applicable:** Can be plugged into any existing GR model.
- **Significant uplift in accuracy:** Demonstrated both in controlled experiments and in the real-world large-scale environment of Alipay.

### 5. In Simple Terms

Imagine teaching a less experienced junior not just to answer questions quickly, but to always explain their reasoning. Then, before the answer goes out, a group of experts reviews and flags anything suspicious. This two-stage process reduces mistakes and increases trust in the output.

### 6. Impact

This methodology has already been deployed at scale in Alipay's Fund and Insurance search, delivering measurable improvements in user clicks and transaction counts 3726302.3731951.pdf.

**In summary:** By teaching our models the reasoning behind relevance (not just the answer), and adding a decisive quality control step after initial retrieval, we greatly reduce hallucinations and boost retrieval precision in complex search scenarios.