# From Prompt Engineering to Prompt Science

**Author:** Chirag Shah  
**Journal:** Communications of the ACM (CACM), Volume 68, Issue 1, January 2025, pages 21-23  
**DOI:** 10.1145/3702021  
**Type:** Viewpoint Article

---

## Explain this paper to me in depth using the Feynman technique, as if you were its author

Hi there! I'm Chirag Shah, and I wrote this viewpoint piece for Communications of the ACM. Let me explain what I mean by moving "From Prompt Engineering to Prompt Science" - it's a really important shift we need to make in how we work with AI systems.

## The Problem: We're Still Just "Hacking" Prompts

Right now, most people approach prompting like they're trying to guess a secret password. They'll try different phrasings, add magic words like "think step by step," or copy prompts they found online, hoping something will work. It's like trying to fix a car by randomly hitting it with a wrench - sometimes it works, but you don't really know why.

This approach - what I call "prompt engineering" - has several problems:

### 1. **It's Ad-hoc**
People just try random things without any systematic approach. There's no method to the madness.

### 2. **It's Not Reproducible**
What works for one person might not work for another. What works today might not work tomorrow when the model gets updated.

### 3. **It's Not Scalable**
You can't build reliable systems on top of techniques that are basically trial and error.

### 4. **We Don't Understand Why Things Work**
When a prompt works, we often have no idea why. This makes it impossible to improve or adapt.

## The Solution: Treat Prompting Like Science

What if we approached prompting the same way we approach any other scientific discipline? What if we applied the same rigor we use for scientific instruments to our prompts?

### What Does "Prompt Science" Look Like?

**Systematic Methodology**: Instead of random trial and error, we need structured approaches to understand what makes prompts effective.

**Reproducible Results**: Our methods should work consistently across different contexts, users, and time periods.

**Theoretical Understanding**: We need to understand the underlying principles - why certain prompts work and others don't.

**Rigorous Evaluation**: We need proper metrics and benchmarks to measure prompt effectiveness.

**Peer Review and Validation**: Just like other scientific work, prompt research should be subject to peer review and independent validation.

## Drawing from Qualitative Research

One of my key insights is that we can learn a lot from qualitative research methods, particularly **qualitative coding**. Here's how:

### Traditional Qualitative Coding
In social science research, when researchers analyze text data (like interview transcripts), they don't just randomly categorize things. They use systematic methods:

1. **Multiple Coders**: Several researchers independently analyze the same data
2. **Intercoder Reliability**: They measure how much the coders agree
3. **Iterative Refinement**: They refine their coding schemes based on disagreements
4. **Theoretical Grounding**: They connect their findings to existing theory

### Applying This to Prompts
We can apply similar principles to prompt development:

1. **Multiple Validators**: Have multiple people test the same prompts
2. **Consistency Metrics**: Measure how consistently prompts work across different conditions
3. **Iterative Improvement**: Systematically refine prompts based on failures
4. **Theoretical Framework**: Develop theories about what makes prompts effective

## Concrete Steps Forward

Based on my research and experience, here's how we can move toward prompt science:

### 1. **Establish Evaluation Frameworks**
We need standardized ways to measure prompt effectiveness that go beyond "it gave me the answer I wanted."

### 2. **Create Reproducible Methodologies**
Develop systematic approaches that others can follow and replicate.

### 3. **Build Theoretical Understanding**
Study the underlying mechanisms - how do language models actually process prompts?

### 4. **Develop Best Practices**
Create guidelines based on empirical evidence, not just intuition.

### 5. **Foster Community Standards**
Establish peer review processes and shared benchmarks.

## Why This Matters

The transition from prompt engineering to prompt science isn't just academic - it has real-world implications:

### **Reliability**
Systems built on scientific principles are more reliable than those built on trial and error.

### **Scalability**
Scientific approaches can be systematically applied across different domains and use cases.

### **Trustworthiness**
When we understand why something works, we can better predict when it might fail.

### **Innovation**
Scientific understanding enables genuine innovation rather than just tweaking existing approaches.

## The Broader Vision

This viewpoint piece is part of a larger call for the AI community to mature in how we approach these powerful tools. We're at a point where AI systems are being deployed in critical applications - healthcare, education, finance, legal systems. We can't afford to rely on ad-hoc approaches.

By treating prompting as a scientific discipline, we can:
- Build more reliable AI systems
- Better understand the capabilities and limitations of language models
- Develop more effective human-AI collaboration methods
- Create systems that are truly trustworthy and accountable

## Connection to My Other Work

This viewpoint connects to my broader research on human-centered evaluation in the LLM era. The same principles that apply to prompt science also apply to AI evaluation more generally - we need systematic, rigorous, and theoretically grounded approaches.

The case studies I've done (like the work on user intent taxonomies and LLM auditing) are examples of what prompt science can look like in practice. They show how we can move beyond ad-hoc approaches to systematic, scientific methods.

## The Path Forward

Moving from prompt engineering to prompt science won't happen overnight. It requires:

1. **Community Buy-in**: Researchers and practitioners need to embrace more rigorous approaches
2. **Tool Development**: We need better tools for systematic prompt development and evaluation
3. **Education**: We need to train people in scientific approaches to prompting
4. **Institutional Support**: Academic and industry institutions need to support this more rigorous approach

But the benefits will be worth it. We'll have more reliable, trustworthy, and effective AI systems that truly serve human needs.

---

*This viewpoint piece argues for a fundamental shift in how we approach prompting - from ad-hoc engineering to systematic science. It's not just about better prompts; it's about building a more reliable and trustworthy AI future.*

## Access Information

**Publication Details:**
- Published in Communications of the ACM (CACM)
- Volume 68, Issue 1, January 2025
- Pages 21-23
- DOI: 10.1145/3702021

**Access:**
- Available through ACM Digital Library (subscription required)
- May be accessible through institutional libraries
- Contact author for potential preprint access