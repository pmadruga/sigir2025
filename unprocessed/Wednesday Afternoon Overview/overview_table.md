## Overview

| Paper & Link                                                                                                                                                                   | Problem Addressed & Summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **RANKERS, JUDGES, AND ASSISTANTS: TOWARDS UNDERSTANDING THE INTERPLAY OF LLMS IN INFORMATION RETRIEVAL EVALUATION**<br>[Link](https://dl.acm.org/doi/10.1145/3726302.3730348) | Examines the risks when LLMs serve both as rankers (choosing results) and judges (scoring relevance) in information retrieval, possibly biasing system evaluation.<br>Finds LLM judges are more lenient than humans, can be biased toward LLM-based rankers, and may miss subtle performance gaps, risking feedback loops that reward model similarity over actual quality.<br>Recommends maintaining human oversight, transparency, and consistent evaluation practices to ensure IR benchmarks reflect genuine user needs, not just LLM preferences. |
| **INSTRUCTRAG: LEVERAGING RETRIEVAL-AUGMENTED GENERATION ON INSTRUCTION GRAPHS FOR LLM-BASED TASK PLANNING**<br>[Link](https://dl.acm.org/doi/10.1145/3726302.3730009)         | Improves LLM planning for complex, multi-step tasks by storing successful problem-solving instructions in a reusable instruction graph.<br>Combines retrieval of instruction paths and RL/ML agents to explore and score candidate plans, enabling adaptive, stepwise guidance for both known and novel tasks.<br>Leads to more flexible, explainable, and rapid few-shot learning for new task types by leveraging structured memory of past solutions.                                                                                               |
| **A UNIFIED RETRIEVAL FRAMEWORK WITH DOCUMENT RANKING AND EDU FILTERING FOR MULTI-DOCUMENT SUMMARIZATION**<br>[Link](https://dl.acm.org/doi/10.1145/3726302.3729884)           | Advances multi-document summarization by automating both query selection and retrieval at the fine-grained Elementary Discourse Unit (EDU) level instead of full sentences or paragraphs.<br>This model-agnostic approach selects important queries and relevant text fragments without human effort, leading to more focused, high-quality summaries.<br>Experiments show its improved retrieval quality and summary informativeness over existing baselines on major summarization datasets.                                                         |
| **RETRIEVAL AUGMENTED GENERATION FOR DYNAMIC GRAPH MODELING**<br>[Link](https://dl.acm.org/doi/10.1145/3726302.3729958)                                                        | Tackles prediction in dynamic graphs (where relationships shift over time) by retrieving and fusing demonstrations—similar node histories—from a temporal and structural perspective.<br>Combines time- and context-aware retrieval with a graph fusion generator to blend broader past experiences, improving predictions for evolving networks.<br>Outperforms prior methods by moving beyond local node histories and capturing dynamic, global trends effectively.                                                                                 |
| **EMPOWERING LARGE LANGUAGE MODEL AGENT THROUGH STEP-LEVEL SELF-CRITIQUE AND SELF-TRAINING**<br>[Link](https://dl.acm.org/doi/10.1145/3726302.3729965)                         | Addresses LLM agents' struggles in complex, multi-step tasks by introducing step-level self-critique within a Monte Carlo Tree Search exploration framework.<br>The agent critiques and refines each action step, not just final outcomes, with all reasoning, refinement, and critique data used for ongoing self-training.<br>Results show improved reliability, solution quality, and self-correction ability, making LLM agents more trustworthy and autonomous in complex problem-solving.                                                        |